from model import (
    initialize_openai_embedding_model,
    initialize_openai_chat_model,
)
from vector_search_utils import (
    perform_similarity_search,
    create_in_memory_vector_search,
    load_url_data,
)
from prompts import SEARCH_PROMPT
from qa import initialize_qa_retriever, initialize_qa
from API_GATEWAY import get_data_from_google_api


def vectorize_document(query: str) -> object:
    """
    The `vectorize_document` function takes a query as input, retrieves data from the Google API based
    on the query, loads the data from the retrieved URLs, creates an in-memory vector search using the
    loaded data and an initialized OpenAI embedding model, and returns the vector search object.

    :param query: A string representing the search query
    :type query: str
    :return: The function `vectorize_document` returns an object of type `vector_search`.
    """
    contexts = get_data_from_google_api(query)
    context_urls = [context["link"] for context in contexts] if contexts else []
    docs = load_url_data(context_urls[:3])
    vector_search = create_in_memory_vector_search(
        docs=docs, embedding=initialize_openai_embedding_model()
    )
    return vector_search


# Function to generate response


def generate_response_from_retriever(
    query: str, vector_search
) -> tuple[str, list[str]]:
    """
    The function `generate_response_from_retriever` takes a query and a vector search as input and
    returns a tuple containing the response generated by the QA system and a list of source documents
    used for retrieval.

    :param query: The `query` parameter is a string that represents the user's input or question that
    they want to ask the QA system. It is the input that will be used to generate a response
    :type query: str
    :param vector_search: The `vector_search` parameter is an instance of a vector search model. It is
    used as the retriever in the QA system to retrieve relevant documents based on the query. The
    `as_retriever()` method is called on the `vector_search` object to convert it into a retriever that
    :return: The function `generate_response_from_retriever` returns a tuple containing two elements.
    The first element is a string representing the result of the question answering system, and the
    second element is a list of strings representing the source documents that were used to generate the
    result.
    """
    qa_system = initialize_qa(
        initialize_openai_chat_model(), vector_search.as_retriever(), SEARCH_PROMPT
    )
    qa_results = qa_system({"query": query})
    return qa_results["result"], qa_results["source_documents"]


def SearchRAG(query:str):
    vector_search = vectorize_document(query)
    response, _ = generate_response_from_retriever(query, vector_search)
    return response

